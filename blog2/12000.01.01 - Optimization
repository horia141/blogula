= Introduction =

\def{Optimization Theory} is the mathematical discipline of which deals with the theory of function \def{minimization}. Let \f{\mathbb{D}} be a set of objects and \f{f} a function from \f{\mathbb{D}} to \f{\mathbb{R}}. The \def{optimization problem} for \f{f}, denoted by \f{\min_{x \in \mathbb{D}} f(x)} is the task of finding the object \f{x^\star \in \mathbb{D}} of minimum value according to \f{f}, or, more precisely \f{x^\star = \arg\min_{x \in \mathbb{D}} f(x) \Rightarrow \forall x \in \mathbb{D} \colon f(x^\star) \leq f(x)}. \f{\mathbb{D}} is called the \def{solution space} or \def{domain}, \f{f} is called the \def{cost function}, a \f{x \in \mathbb{D}} is called a \def{solution} and \f{x^\star} is called an \def{optimal solution}.

Many problems can be formulated as optimization problems with \f{\mathbb{D}} having a wildly complex structure. For a great deal of purposes, it suffices to see \f{\mathbb{D}} as a subset of \f{\mathbb{R}^n} (continuous problems) or \f{\mathbb{Z}^n} (discrete problems). The way to specify how this subset looks is by using \def{constraint functions}, which are indicator function on \f{\mathbb{R}^n} and which are used to filter all the points in \f{\mathbb{R}^n} in order to form \f{\mathbb{D}}. Let \f{c_1,c_2,\dots,c_m} be constraint functions. Then \f{\mathbb{D} = \{ x \in \mathbb{R}^n \given c_1(x) ~\text{and}~ \dots ~\text{and}~ c_m(x) \}}. In the most degenerate case, a single indicator function which tests membership in \f{\mathbb{D}} by its specific mechanism is used, but, in practice, the majority of problems can be expressed with many simple constraint functions. The formalism holds. In fact, it is customary to reffer to the whole of \f{\mathbb{R}^n} or \f{\mathbb{Z}^n} as the solution space and reffer to any member as a solution. The set \f{\mathbb{D}} which satisfies all the constraints is called the \def{feasible solution space} or \def{feasible domain}, while a member is called a \def{feasible solution}. The optimization problem is then to find the smallest value feasible solution. This is just another way to refer to things, though, for cases where problems are all very similarly structured, and it makes sense to think of them as working on \f{\mathbb{R}^n} plus some restrictions.

= Linear Programming =

A \def{linear optimization problem} or \def{linear program} is a function maximization problem where the cost function is linear and the constraints are linear. More precisely, a linear program consists of an objective function \f{c_1x_1 + \dots + c_nx_n} and linear inequalities \f{a_{11}x_1 + \dots a_{1n}x_n \leq b_1} and \f{\dots} and \f{a_{m1}x_1 + \dots a_{mn}x_n \leq b_m}. [matrvix notation] [>= equalities to <=] [== equalities to double inequalities] [max to min]

Let \f{L \colon (c,A,b)} be a linear program and \f{x \in \mathbb{R}^n} a solution for \f{L}, for the rest of this chapter.

We say that \f{x} is a \def{feasible solution} of \f{L} if it satisfies all linear inequalities specified by \f{L}. We say that \f{L} is \def{feasible} if \f{L} has feasible solutions. We say that \f{x} is an \def{optimal solution} of \f{L} if it has a higher cost than all other feasible solutions, or, more precisely \f{\forall y \in \mathbb{R}^n \colon y ~\text{feasible} \Rightarrow c^Tx \geq c^Ty}. We say that \f{L} is a \def{bounded linear program} if there exists a constant \f{\mathcal{M} \in \mathbb{R}} such that for all feasible solutions \f{x} we have \f{c^Tx \leq M}.

The function \f{c^Tx} describes almost a plane. For a fixed \f{b} all the points \f{c^Tx = b} are a \f{n+1}-dimensional plane consisting of all the points orthogonal to \f{c} and at a certain distance from the origin, that is, of a certain cost. Going in the direction of \f{c} will increase this cost while going in the opposite direction will decrease the cost. Moving orthogonal to \f{c} (on one of the planes described with \f{c}) will keep the same cost.

Linear programming contains in some sense solving a linear system.

Let \f{L \colon max\{c^Tx \given x \in \mathbb{R}^n ~\text{and}~ Ax = b \}} with \f{b \in \im(A)} and \f{c \in \ker(A) \setminus \{0\}}. \f{L} is feasible and unbounded.

A set \f{P} of vectors in \f{\mathbb{R}^n} is a \def{polyhedron} if \f{P = \{ x \in \mathbb{R}^n \given Ax \leq b\}} for some matrix \f{A} and some vector \f{b}. The empty set \f{P = \emptyset = \{ x \in \mathbb{R}^n \given \textbf{0}^Tx \leq -1\}}. The set \f{P = \{ x \}} is a polyhedron. The set defiened by \f{a \in \mathbb{R}^n \setminus \{ \textbf{0} \}} and \f{\beta \in \mathbb{R}} as \f{\{ x \in \mathbb{R}^n \given a^Tx \leq \beta \}} is a polyhedron (the half-space). The set defiened by \f{a \in \mathbb{R}^n \setminus \{ \textbf{0} \}} and \f{\beta \in \mathbb{R}} as \f{\{ x \in \mathbb{R}^n \given a^Tx = \beta \}} is a polyhedron (the hyper-plane). The set of feasible solutions of a linear program is a polyhedron. We say that an inequality \f{a^Tx \leq \beta} is \def{valid} for a polyhedron \f{P} if each \f{x^\star \in P} satisfies \f{a^Tx^\star \leq \beta}. We say that an inequality \f{a^Tx \leq \beta} is \def{active} at \f{x^\star} if \f{a^Tx^\star = \beta}.

We say that \f{x^\star} is a \def{vertex} of \f{P} if there exists an inequality \f{L \colon a^Tx \leq \beta} such that \f{L} is valid for \f{P} and \f{L} is active at \f{x^\star} and \f{L} is not active for any other point in \f{P}. Intuitively, \f{x^\star} is a vertex if we can find a half-space such that the polyhedra \f{P} touches the half-space only at \f{x^\star}. Alternatively, \f{x^\star} is a vertex iff there exists \f{c \in \mathbb{R}^n} such that \f{x^\star} is the unique optimal solution of the linear program \f{\max \{ c^Tx \given x \in P \}}. This definition is not very useful from an algorithmic point of view.

We have that \f{I = \{ i \in \hcrange{1}{m} \given a_i^Tx^\star = b_i \}} is the set of indices of inequalities active at \f{x^\star \in \mathbb{R}^n} not only in \f{P}. Let \f{A_I = A(I,:)} and \f{b_I = b(I)}. Then \f{A_Ix \leq b_I} is the sub-system of inequalities active at \f{x^\star}.

A point \f{x^\star \in \mathbb{R}^n}, not necesarily feasible, is a \def{basic solution}, if \f{rank(A_I) = n}. If \f{x^\star \in P} then \f{x^\star} is an \def{basic feasible solution}.

Let \f{P = \{x \in \mathbb{R}^n \given Ax \leq b \}} and \f{x^\star \in P}. \f{x^\star} is a vertex iff \f{x^\star} is a basic feasible solution.

For ``\f{\Rightarrow}''. If \f{x^\star} is a vertex then we have an \f{\alpha \in \mathbb{R}^n} and \f{\beta \in \mathbb{R}} such that \f{\alpha x^\star \leq \beta} is valid for \f{P}, active for \f{x^\star} and not active for any other point in \f{P}. Let \f{I} be the set of indices of inequalities from \f{Ax \leq b} which are active at \f{x^\star}. \textbf{Version 1}. We assume, without proof, that \f{\alpha \in \text{Row}(A_I)} - otherwise we can make it so that the uniqueness of \f{x^\star} is violated. Assume, by contradiction, that the rank of \f{A_I} is not \f{n}, but is, in fact, strictly less than \f{n}. Then, the system \f{A_Ix \leq b_I} has an infinity of solutions, being underdetermined, but with \f{x^\star} as a known solution. The space of solutions for it has the form \f{S_I = \{x^\star + x \given x \in \text{Null}(A_I) \} \subseteq P} (since \f{Ax^\star + Ax = Ax^\star \leq b}. Let \f{\overline{x} = x^\star + x \in S_I} and \f{\alpha = \sum_{i=1}^m {\overline{\alpha}_j A_I^j} = A_I^T\overline{\alpha}} where \f{m} is the number of rows in \f{A_I}. Then, we get \f{\alpha^T\overline{x} = (A_I^T\overline{\alpha})^T(x^\star + x) = \overline{\alpha}^T A_I (x^\star + x) = \overline{\alpha}^T (A_I x^\star + A_I x) = \overline{\alpha}^T A_I x^\star = (A_I^T \overline{\alpha})^T x^\star = \alpha^T x^\star = \beta}. We have found another active point in \f{P} for \f{\alpha x \leq \beta}, which is a contradiction. \textbf{Version 2}. Since \f{x^\star} is a vertex, it is the unique maximum point of a LP with cost function \f{c} of the form \f{\max\{ c^Tx \given Ax \leq b\}}. Since \f{A_I} does not have full rank, we have that \f{\{ \textbf{0} \} \subset \text{Null}(A_I)} and we can find \f{d \in \text{Null}(A_I) \setminus \{ \textbf{0} \}} such that for properly chosen \f{\epsilon} both \f{x^\star + \epsilon d} and \f{x^\star - \epsilon d} satisfy \f{Ax \leq b}. Since \f{c^Tx^\star} is the unique maximum we have \f{c^Tx^\star > c^T(x^\star + \epsilon d)} or \f{\epsilon c^Td > 0} and \f{c^Tx^\star > c^T(x^\star - \epsilon d)} or \f{\epsilon c^Td < 0}. This is a contradiction, and we have that \f{A_I} must have full rank.
For ``\f{\Leftarrow}''. If \f{x^\star} is a basic feasible solution, then we can find a set \f{I} of inequalities from \f{Ax \leq b} such that \f{A_I} has rank \f{n} and \f{A_Ix \leq b_I} is active at \f{x^\star}. This means that \f{x^\star} is the unique solution to \f{Ax = b} and \f{A_Ix = b_I}. This means that for no other point \f{\overline{x} \in P} do we have \f{A_Ix = b_I}. This means that there is an \f{A_I^j} such that \f{(A_I^j)^Tx \leq b_I^j}. We can then build \f{\alpha = \sum_{i=1}^mA_I^i} and \f{\beta = \sum_{i=1}^m b_I^i} where \f{m} is the number of rows in \f{A_I} and \f{m \geq n}. We have that for \f{\overline{x}} the inequality holds as \f{\alpha^T\overline{x} = (\sum_{i=1}^mA_I^i)^Tx = \sum_{i=1}^m(A_I^i)^Tx} and term is smaller than or equal to the respective \f{b_I^i}, except for the one corresponding to \f{A_I^j} which is strictly smaller than \f{b_I^j} and therefore the sum is strictly smaller than \f{\sum_{i=1}^m b_I^i = \beta}. This means that \f{\alpha^Tx \geq \beta} is valid for \f{P}. Furthermore, the equality holds only for \f{x^\star}, therefore the inequality is active for \f{x^\star} and not active for any other point in \f{P}. Thus, \f{x^\star} is a vertex.

Basically, the intersection of \f{n} linearly independent inequalities (planes) form a vertex.

\def{FeasibleBoundedLPVertexFullRankOptimalSolution} Let \f{\max\{c^Tx \given x \in \mathbb{R}^n \text{ and } Ax \leq b \}} be feasible and bounded LP with \f{\rank(A) = n}. The LP has an optimal solution that is a vertex.

Let \f{\overline{x} \in P} be a feasible solution which is not a basic feasible solution / vertex. Therefore, we can split \f{A} into a part \f{(A_A,b_A)} which is active for \f{\overline{x}} and a part \f{(A_I,b_I)} which is inactive for \f{\overline{x}}. The rank of \f{A_A} is lower than \f{n}, since \f{\overline{x}} is not a vertex, by \thmref{VerticesBasicFeasibleSolutions}. Therefore \f{\{ \textbf{0} \} \subset \text{Null}(A)}. We can select a vector \f{d \in \text{Null}(A) \setminus \{ \textbf{0} \}} and find a \f{\lambda} such that \f{\overline{x} + \lambda d \in P}. Now, \f{A_A(\overline{x} + \lambda d) = A_A \overline{x} = b_A}, therefore \f{(A_A,b_A)} is active for \f{\overline{x} + \lambda d} as well. The cost for it is \f{c^T\overline{x} + \lambda c^Td}. Now, we select, without loss of generality \f{d} such that \f{c^Td \geq 0}. If \f{c^Td > 0}, then, going in the direction of \f{d} from \f{\overline{x}} with increasing \f{\lambda} we will increase the cost. Since the problem is bounded, we will reach another linear inequality \f{\alpha x \leq \beta}. The point \f{\overline{y} = \overline{x} + \overline{\lambda} d} is the point after which increasing \f{\lambda} will result in a violation of \f{\alpha x \leq \beta}. This inequality is therefore not in \f{(A_A,b_A)} because these inequalities work for all \f{\lambda}s, and it must be in \f{(A_I,b_I)}. The inequalities \f{([A_A^T \given \alpha]^T,[b_A \given \beta])} is therefore active for \f{\overline{y}}, is has rank increased by \f{1} because \f{\alpha} is linearly independent of \f{A_A} (otherwise we could write \f{\alpha} as a sum of elements in \f{A_A} and every \f{\lambda} would have been good, because the inequality would have been kept since \f{\alpha^Td = 0}) and we have that \f{c^T\overline{y} > c^T\overline{x}}. If \f{c^Td = 0} we have the same process, but \f{c^T\overline{y} = c^T\overline{x}}. Overall, we can find an \f{\overline{y}} with greater than or equal cost and larger rank for inequalities which are active. We can repeat the process at most \f{n} times and we'll get a vertex at the end, which will have the largest cost.

\def{FeasibleBoundedLPVertexOptimalSolution} Let \f{\max\{c^Tx \given x \in \mathbb{R}^n \text{ and } Ax \leq b \}} be feasible and bounded LP. The LP has an optimal solution.

We transform the original program to the equivalent \f{\max\{ c^Tx \given x \in \mathbb{R}^n \text{ and } A(x_1 - x_2) \leq b \text{ and } x_1 \geq 0 \text{ and } x_2 \geq 0 \}}. The matrix \f{A' = [A -A \given -I_n 0 \given 0 -I_n]} has rank \f{2n}, therefore this program is feasible and bounded and has a full rank inequality matrix. By \thmref{FeasibleBoundedLPVertexFullRankOptimalSolution} we have that it has an optimal solution that is a vertex. This means that the original has an optimal solution, but it is not necessary a vertex.

What we have established is that for feasible and bounded LPs (which are the ones we can actually ``solve'' in principle), optimal solutions exist, and they are vertices if \f{\rank(A) = n} or we can transform to a form with \f{2n} variables but with full rank. Moreover, since being a vertex implies being a basic feasible solution, each point is defined by a set of inequalities which are active for it, and from which, sets of \f{n} linearly independent inequalities can be formed. Since this goes in the other way, one can look at all the \f{\binom{m}{n}} sets of linear inequalities, solve for them, and if they have a solution, and if this solution is feasible, use them as a vertex and candidate optimal solution.  If there are no feasible solutions found, then the LP is infeasible, otherwise the feasible solution of highest value is returned. The algorithm has complexity \f{O(m^n)} however or \f{O(2^n)} (crude bound for \f{m = 2n}), which is exponential.

== The Simplex Algorithm ==

So, \f{x^\star \in P} is a vertex iff the subsystem of active constraints at \f{x^\star} \f{\hat{A}x \leq \hat{b}} satisfies \f{\rank(\hat{A}) = n} iff \f{\exists B \subseteq \hcrange{1}{m}} with \f{\abs{B} = n} such that \f{A_B} is non-singular and \f{A_B x^\star = b_B} (and \f{x^\star = A_B^{-1} b_B)}.

We say that two vertices \f{x_1} and \f{x_2} of \f{P = \{ x \in \mathbb{R}^n \given Ax \leq b \}} are \def{adjacent} if there exist \f{n - 1} linearly independent inequalities of \f{Ax \leq b} active at both \f{x_1} and \f{x_2}.

\def{Condition adjancency} \f{P \subseteq \mathbb{R}^n} be a polyhedron and \f{x_1} and \f{x_2} distinct vertices. \f{x_1} is \def{adjacent} to \f{x_2} iff there exists \f{c \in \mathbb{R}^n} such that the set of optimal solutions of \f{\max \{ c^Tx \given x \in P \}} is the convex combination of \f{x_1} and \f{x_2} \f{\{ \lambda x_1 + (1 - \lambda) x_2 \given \lambda in \mathbb{R} \text{ and } 0 \leq \lambda \leq 1 \}}.

Let us first prove \f{\Rightarrow}. Let \f{I} be the set of \f{n-1} constraints active at both \f{x_1} and \f{x_2}. The proof has \f{4} parts. First, construct \f{c = \sum_{j=1}^{n-1} A_{I_j}}. An optimal solution \f{x^\star} for \f{\max\{ c^T x \given Ax \leq b \}} must have that \f{A_Ix \leq b_I} is active at \f{x^\star}. Why? Consider \f{x^\star} such that there is at least one \f{i \in I} such that \f{A_{I_i}^T x^\star < b_{I_i}}. Then, the cost is \f{c^T x^\star = \sum_{j=1}^{n-1} (A_{I_j}^T x^\star < \sum_{j=1}^{n-1} b_{I_j}}. But, the cost for \f{x_1} is, by the same argument, \f{c^T x_1 = \sum_{j=1}^{n-1} b_{I_j}}, and, therefore, larger then that for the so-called optimal solution. Of course, having an \f{i \in I} such that \f{A_{I_i}^T x^\star > b_{I_i}} is out of the question, as that would violate the constraints. We have reached a contradiction. Second, the null-space of \f{A_I} has dimension \f{1} and we can choose a non-null vector \f{d} from this such that \f{x^\star = x_1 + d}, and \f{A_I x \leq b_I} is active at \f{x^\star} and \f{A x \leq b_I} is valid for \f{x^\star}. Thirdly, notice that \f{x_2 - x_1 \in \text{Null}(A_i)}, because \f{A_I (x_2 - x_1) = 0}. Since the null-space has dimension \f{1}, we can expresess any \f{d} as \f{d = \lambda (x_2 - x_1)}. We thus write, \f{x^\star = x_1 + \lambda (x_2 - x_1)} which is a form equivalent to the one we had before. Fourthly, we must have that \f{0 \leq \lambda \leq 1}. If \f{\lambda < 0} we can find an inequality \f{J \not\in I} which is active at \f{x_1} and which is violated [do math here]. If \f{\lambda > 1} we have \f{\mu = 1 - \lambda < 0} and \f{x^\star = x_2 + \mu (x_1 - x_2)} and the same situation with \f{x_2}.

The Simplex algorithm is technically simple: We start with a vertex \f{x^\star}. While \f{x^\star} is not optimal, we find an adjacent vertex \f{x'} adjacent to \f{x^\star} with \f{c^Tx' > c^Tx^\star}. We then update \f{x^\star \leftarrow x'}. If we can't find such an \f{x'} then the LP is unbounded.

A subset \f{B \subseteq \hcrange{1}{m}} with \f{\abs{B} = n} and \f{A_B} non-singular is called \def{basis} of the LP. If \f{A_B^{-1}b_B} is feasible, then \f{B} is called \def{feasible basis}. A vertex is represented by a basis \f{B}, but there can be several such bases. A program is \def{degenerate} if there exists \f{x^\star \in \mathbb{R}^n} such that there are more than \f{n} constraints in \f{Ax \leq b} that are active at \f{x^\star}. A basis \f{B} is called \def{optimal} if it is feasible and the unique \f{\lambda \in \mathbb{R}^m} with \f{\lambda^T A = c^T} and \f{\lambda_i = 0} for all \f{i \not\in B} satisfies \f{\lambda \geq 0} (it is unique because \f{\lambda} is the representation of \f{c} in terms of \f{A} - we have \f{A^T\lambda = c} or \f{c = \sum_{i=1}^m\lambda_i A_ib}). This means that \f{\lambda_B^T A_B = c^T} or \f{c = \sum_{i \in B}\lambda_i A_i} and \f{\lambda_B^T = c^T A_B^{-1}}.

\def{ConditionOptimalSolution} \f{L} be a linear program and \f{B} an \def{optimal basis} for \f{L}. \f{x^\star = A_B^{-1}b_B} is an optimal solution for \f{L}.

Consider any point \f{x \neq x^\star}. Since \f{B} is optimal, the unique \f{\lambda} such that \f{\lambda^T A = c^T} or \f{A^T \lambda = c} has only non-negative entries. Assume \f{c^T x^\star > x^T x} or \f{\lambda_B^T A_B x^\star > \lambda_B^T A_B x} or \f{\lambda_B^T A_B A_B^{-1} b_B > \lambda_B^T A_B x} or \f{\lambda_B^T b_B > \lambda_B^T A_B x}. Since \f{x^\star} is a vertex, any other point will have some of the inequalities in \f{A_B} made strict \f{A_B x \leq b_B} will only be valid there. Therefore the previous inequality hold.

What the following theorem states is that, if we have a case where all points lie are active for at most \f{n} inequalities (lie at the interesection of at most \f{n} inequality hyper-planes - this is non-degenerate), then, if the cost vector is such that it is not in the ``positive'' area of the planes at a non-singular set of inequalities (a vertex), then we can find a better solution. [see intuitive picture].

\def{ConditionNonOptimalSolution} \f{L} be a non-degenerate linear program and \f{B} is a feasible but not optimal basis. \f{x^\star = A_B^{-1}b_B} is not an optimal solution for \f{L}.

The ideea is to find a certain direction of movement from \f{x^\star} such that we have a higher cost. We have that \f{A_{i \in B}^T x^\star = b_{i \in B}} and \f{A_{i \not\in B}^T x^\star < b_{i \not\in B}} because \f{L} is non-degenerate. Now, because \f{B} is not optimal, there is one \f{J \in B} such that \f{\lambda_J < 0}. We have that \f{\rank{A_{B \setminus \{J\}}} = n - 1}. We can then select a non-null \f{d} from the nullspace of \f{A_{B \setminus \{J\}}} and have that \f{A_B d = [ 0 ~ 0 ~ \dots ~ 0 ~ A_J^T d ~ 0 ~ \dots ~ 0 ]}. For convenience, we can select \f{d} such that \f{A_J^T d = -1}. Now, if we move in the direction of \f{x^\star + d} we'll have an increase in cost (proof will follow). But we probably will invalidate some inequalities. Therefore, we will move by \f{x^\star + \epsilon d}, where \f{\epsilon > 0} is chosen such that \f{A (x^\star + \epsilon d) \leq b}. For \f{i \in B \setminus \{J\}} we have \f{A_i^T x^\star = b_i} and \f{\epsilon A_i^T d = 0}, therefore this set of inequalities is active. For \f{i = J} we have \f{A_J^T x^\star = b_J} and \f{\epsilon A_J^T d = -\epsilon < 0}, therefore the inequality is valid for \f{J}. For \f{i \not\in B} we have \f{A_i^T x^\star < b_i} and \f{\epsilon A_i^T d \neq 0}. We must select \f{\epsilon} such that for each \f{i \not\in B} we have \f{\epsilon A_i^T d \leq b_i - A_i^T x^\star}. That is, \f{\epsilon} must be chosen so that the terms added to the \f{m - n} non-active inequalities at \f{x^\star} makes \f{x^\star + \epsilon d} at most active. In other words we must choose \f{\epsilon \leq \min_{i \not\in B} (b_i - A_i^T x^\star) / (A_i^T d)}. We have thus proven that \f{x^\star + \epsilon d} is feasible, with approprate \f{\epsilon}, for which we have a clear selection procedure. Now, the cost is \f{c^T(x^\star+ \epsilon d) = \lambda_B^T A_B (x^\star + \epsilon d) = c^T x^\star + \epsilon \lambda_B^T A_B d = c^T x^\star + \epsilon \lambda_B^T [0 ~ \dots ~ 0 ~ -1 ~ 0 ~ \dots ~ 0 ] = c^T x^\star - \epsilon \lambda_J > c^T x^\star} since \f{\lambda_J < 0}. Thus, this new feasible solution has higher cost.

So, if \f{L} is non-degenerate, we have an equivalence between optimal basis and optimal vertices. We also know, by the proof of \thmref{ConditionNonOptimalSolution} how to select a \f{d} of better cost. Let's say we search for \f{d} such that \f{A_J^Td = -1}. We'll control the thing through \f{\epsilon}. Let \f{K = \{ k \in \hcrange{1}{m} \given A_k^T d > 0 \}}. If this set is empty, the LP is unbounded. If it is not empty, how large can we make \f{\epsilon} before we hit \f{k \in K}? It is such that \f{A_K^T (x^\star + \epsilon_k d) = b_k} and \f{\epsilon_k = (b_k - A_k^Tx^\star) / A_K^Td}. So \f{\epsilon = \min_{k \in K} \epsilon_k}. Therefore, our new vertex \f{x' = x^\star + \epsilon d}. Then \f{B' = B \setminus \{J\} \cup \{k^\star\}} is a basis, because \f{d \perp A_j} for \f{j \in B \setminus \{J\}}, \f{d \not\perp A_{k^star}} because, by construction \f{A_{k^\star}^Td > 0}, therefore \f{A_{k^star}} is not a linear combination of \f{A_j} for \f{j \in B \setminus \{ J \}} otherwise we'd have that \f{d} was \f{\perp} on it too. Furthermore \f{x'} is a vertex, and is adjacent to \f{x^\star}.

The Simplex Algorithm for a non-degenerate LP can then become. Start with a vertex \f{x^\star}. While \f{x^\star} is not optimal, find it's basis \f{B} and find \f{\lambda \in \mathbb{R}^m} such that \f{\lambda_i = 0} for \f{i \not\in B} and \f{\lambda_i \neq 0} for \f{i \in B}. If there is no \f{\lambda_{i \in B} < 0} then the solution \f{x^\star} is optimal and we output it. Otherwise, let \f{J} be the index such that \f{\lambda_J < 0}. Find a \f{d} from the null space of \f{A_{B \setminus \{J\}}} with \f{A_i^Td = 0} for \f{i \in B \setminus \{J\}} and \f{A_J^Td = -1}. Determine \f{K = \{ k \in \hcrange{1}{m} \given A_K^T > 0\}}. If this is empty, the LP is unbounded. Otherwise, let \f{\epsilon^\star = \min_{k \in K} (b_k - A_k^Tx^\star) / A_K^Td} and update \f{x^\star = x^\star + \epsilon^\star d}.

The Simplex Algorithm for a non-degenerate LP can be posed in terms of feasible bases as well. Start with a feasible basis \f{B}. While \f{B} is not optimal, find \f{\lambda \in \mathbb{R}^m} such that \f{\lambda_i = 0} for \f{i \not\in B} and \f{\lambda_i \neq 0} for \f{i \in B}. If there is no \f{\lambda_{i \in B} < 0} then the solution \f{x^\star} is optimal and we output it. Otherwise, let \f{J} be the index such that \f{\lambda_J < 0}. Find a \f{d} from the null space of \f{A_{B \setminus \{J\}}} with \f{A_i^Td = 0} for \f{i \in B \setminus \{J\}} and \f{A_J^Td = -1}. Determine \f{K = \{ k \in \hcrange{1}{m} \given A_K^T > 0\}}. If this is empty, the LP is unbounded. Otherwise, let \f{k^\star = \arg\min_{k \in K} (b_k - A_k^Tx^\star) / A_K^Td} and update \f{B} to \f{B \setminus \{ J \} \cup \{ k^\star \}}.

\def{NonDegenerateTerminationSimplexAlgorithm} \f{L} be a non-degenerate linear program. The simplex algorithm terminates with \f{L} as input.

The proof consists of stating that no basis \f{B} is revisited. Each basis \f{B} has an associated vertex \f{x^\star} of a certain cost. According to the algorithm, at each step, we check if we can move to another vertex. If we can't, then it is the case that the program is unbounded, and we have terminated. If we can, we are going to move to a solution of a strictly higher cost (see proof of \thmref{ConditionNonOptimalSolution}), therefore, we cannot return to a current basis, since every other further basis will have higher cost, and there is be no way to go to a lower cost solution.

In the degenerate case, the problem is that when we extend the basis using the Simplex algorithm from above, we might stay at the current vertex and make no progress, because there will be other inequalities, with \f{b_k - A_k^Tx^\star = 0}, which are added, and we will keep cycling at the same cost, and the algorithm will not terminate. \def{Bland's rule} is a way to avoid this problem, which assures we terminate. We will select the index \f{J} for \f{\lambda_J < 0} to be the smallest index. Similarly we select \f{k \in K} as the smallest index from \f{K}. This is an \def{pivoting rule}.

\def{GeneralTerminationSimplexAlgorithmBlandsRule} \f{L} be a linear program. The simplex algorithm with Bland's rule terminates with \f{L} as input.

The proofs is a little bit tricky. I'll give a sktech for now. Suppose, by contradiction, that we did have a cycle, and it was between basis \f{B_i} and \f{B_j} at steps \f{i} and \f{j}. At each step a index is taken out of the basis and another put in. Let \f{J} be the largest such index. Contradictions will ensue.

The last issue is finding the initial vertex / feasible basis. We build a linear program which is easy to solve and whose solution is our initial vertex. Assume we have an LP in the form \f{\max c^Tx} with \f{Ax \leq b} and \f{x \geq 0}. We can transform any program in such a form by \f{u - v}. We split our problem into \f{A_1x \leq b_1} with \f{b_1 \geq 0} and \f{A_2x \leq b_2} with \f{b_2 < 0} and \f{b_2 \in \mathbb{R}^{m_2}} and build \f{\min \sum_{i=1}^m b_2} subject to \f{A_1x \leq b_1} and \f{A_2x \leq b_2 + y} and \f{x,y \geq 0} and \f{y \leq \abs{b_2}}. A vertex for this is \f{(x^\star,y^\star) = (0,\abs{b_2})}. Notice that the original program is feasible if the optimal value of the second program is \f{0}. If we solve the second program, and obtain an optimal vertex, we can use \f{x^\star} obtained from it as the initial vertex. If we don't find such an optimal solution, we have that the program is infeasible.

The final algorithm is. Given \f{\max\{x^Tx \given x \in \mathbb{R}^n, Ax \leq b \}} we rewrite it as \f{\max \{ x^T(y - z) \given y,z \in \mathbb{R}^n, A(y - z) \leq b, y,z \geq 0 \}}. We then find an initial vertex using the previous method, and have \f{x^\star = (y^\star - z^\star)}. If the optimal cost is not \f{0}, we assert that the original LP is infeasible. Otherwise, we use the simplex method using our initial vertex. The outcome of this is an optimal solution or an assertion that LP is unbounded.

We thus have a terminating algorithm which will output infeasible, unbounded or the optimal solution for any arbitrary linear program.

The runtime of an itertion of the simplex algorithm for rational matrices is: compute \f{\lambda_B} in \f{O(n^2)}, compute \f{K = Ad} in \f{O(mn)}, select the element that enters the basis in \f{O(n^2 + mn)} (plus \f{Ad} which is known). We can write \f{A \in \mathbb{Q}^{\hctimes{m}{n}}} as \f{A = 1/Q A'} where \f{Q} is the product of denominator for each element in \f{A} and \f{{A_{ij}}' = QA_{ij}}. What is the size of \f{A}? We know that \f{\abs{\det{A}} \leq \Sigma_{i=1}^n \norm{a_i}_2 \leq n^{n/2} B^n}, where B is an upper bound on the absolute values of entries of \f{A} (the Hadamard Bound). If \f{A \in \mathbb{Z}^{\hctimes{n}{n}}} is integral then \f{\text{size}(\det{A}) = O(n\log{n} + n\text{size}(B))}. Thus the size of \f{A^{-1}} is polynomial in the size of \f{A} (considering we compute \f{A^{-1}} by Cramer's Rule). We d on't have to compute, however \f{A_B^{-1}} at each iteration. We can use the previous version and update it. We compute \f{a_{b_k}^T A_{B'}^{-1} = (v1,\dots,v_k,\dots,v_n)}. Now, for each column \f{i \neq k}, we substract \f{v_i / v_k} times column \f{k} from column \f{i} and divide column \f{k} by \f{v_k}. This is \f{O(n^2)} in total.

Then, one iteration of the simplex algorithm requires a total number of \f{O(mn)} operations on rational numbers whose size is polynomial in the input data.

How many iterations does the simplex algorithm require? For many popular pivoting rules, researchers have established exponential \def{lower bounds} on the number of iterations. On the other hand, on an average problem, the algoritm is efficient on an average program, with \f{O(m)} iterations. This is far better than the initial algorithm.

The Ellipsoid method of Khachiyan, is a method which, if all coefficients are bounded by \f{\Phi}, the linear problem can be solved with a polynomial in \f{m + n + \Phi} number of operations. Furthermore, all numbers in the course of the algorithm have polynomial size in \f{m + n + \Phi}. 

For a certain polyhedron, we can construct an associated graph, with its vertices as the nodes and an edge between two nodes if the vertices are adjacent. We wish to obtain bounds on the diameter of this graph, because this bounds the number of iterations of the simplex method. We have \f{\delta(n,m)} as the largest diameter of a polyhedral graph of a with \f{n} variables and \f{m} inequalities. The best bound, by Kalai and Kleitman, is \f{\delta(n,m) \leq m^{1 + \log{n}}} - a quasi-polynomial bound.

\def{ConnectednessGraphPolyhedrons} \f{P = \{ x \in \mathbb{R}^n \given Ax \leq b \}} be a polyhedron with vertices and \f{G_P} its associated graph. \f{G_P} is connected and any vertex in a path between \f{u} and \f{v} the set of inequalities active at both \f{u} and \f{v} are active as well.

\f{G_P} is connected iff for any nodes \f{u} and \f{v} we can find a path between them. This translates that we can reach any vertex from any other vertex of the polyhedron.

We can partition \f{V} into a set of layers, according to their distance from a node \f{s}. The nodes in the last layer are at maximum distance. If \f{s,t} satisfy the diameter, then \f{t} is in the fartherst layer from \f{s}.

== Linear Program Duality ==

If we have a linear program \f{\max\{c^Tx \given Ax \leq b\}} we have that for \f{\lambda \in \mathbb{R}^m} and \f{\lambda \geq 0} we have \f{(\lambda^TA)x \leq \lambda^Tb} is valid for \f{P = \{ x \in \mathbb{R}^n \given Ax \leq b \}}. If, in addition \f{\lambda^T A = c^T} then we have \f{c^T x \leq \lambda^T b} is valid for all feasible solutions. \f{\lambda^T b} is an \def{upper bound} on objective values of feasible solutions. We can find the least upper bound by a liniear program of the form \f{\min\{b^T \lambda \given A^T \lambda = c \text{ and } \lambda \geq 0\}}. This is called the \def{dual linear program} while the original is the \def{primal program}. The solution of this program is \f{\lambda \in \mathbb{R}^m}. 

\def{Weak Duality} \f{L \colon \max\{c^Tx \given x \in \mathbb{R}^n \text{ and } Ax \leq b \}} be a linear program and \f{\overline{L} \colon \min\{b^Ty \given y \in \mathbb{R}^m \text{ , } A^Ty = c \text{ and } y \geq 0 \}} be its dual and \f{x^\star \in \mathbb{R}^n} is feasible for \f{L} and \f{y^\star \in \mathbb{R}^m} is feasible for \f{\overline{L}} then \f{c^Tx^\star \leq b^Ty^\star}

Since \f{y^\star} is feasible for \f{\overline{L}} we have that \f{A^Ty^\star = c}. We then have \f{c^Tx = (A^Ty^\star)^Tx = (y^\star)^TAx}. Since \f{x^\star} is feasible for \f{L} we have \f{Ax \leq b}, therefore we have \f{y^\star Ax \leq (y^\star)^T b = b^Ty^\star}, which is what we wanted to prove.

This theorem states that the cost of any feasible solution to the dual program is larger than the cost of any feasible solution to the primal program. Obtaining optimal solutions of the dual will give a tight upper bound on the primal program. For linear programs these bounds will be exact (the infimum of the set of costs of the dual is equal to the supremum of the set of costs of the primal). Furthermore, \f{c^Tx \leq b^Ty^\star} is active for all \f{x \in P_L}.

\def{Strong Duality} \f{L \colon \max\{c^Tx \given x \in \mathbb{R}^n \text{ and } Ax \leq b \}} be a bounded and feasible linear program and \f{\overline{L} \colon \min\{b^Ty \given y \in \mathbb{R}^m \text{ , } A^Ty = c \text{ and } y \geq 0 \}} be its dual. Then there exists \f{x^\star \in \mathbb{R}^n} which is feasible for \f{L} and \f{y^\star \in \mathbb{R}^m} which is feasible for \f{\overline{L}} such that \f{c^Tx^\star = b^Ty^\star}.

First, assume \f{\rank{A} = n}. Then, since \f{L} is feasible and bounded, we have, by \thmref{FeasibleBoundedLPVertexOptimalSolution}, that \f{L} has an optimal solution. Let \f{x^\star} be this solution. If we run the Simplex algorithm we will obtain \f{B \subseteq \hcrange{1}{m}} such that \f{x^\star = A_B^{-1}b_B}. We have an associated \f{\lambda \in \mathbb{R}^m} with \f{\lambda_i \geq 0} for all \f{i \in \hcrange{1}{m}} and \f{\lambda_i = 0} for all \f{i \not\in B}, since \f{B} is an optimal feasible basis. Furthermore we have \f{A^T\lambda = c} and \f{\lambda \geq 0} means that \f{\lambda} is a feasible solution for \f{\overline{L}}. We then have \f{\lambda^T A = c^T} or \f{\lambda^T A x^\star = c^T x^\star} or \f{\lambda_B^T A_B x^\star = c^T x^\star} or \f{\lambda_B^T b_B = c^T x^\star} or \f{\lambda^T b = c^T x^\star} or \f{b^T \lambda = c^T x^\star} since \f{A_B x^\star = b_B} and \f{\lambda_B^T b_B = \lambda^T b}. We have thus found our \f{y^\star = \lambda}.
Second, assume \f{\rank{A} < n}. We can build the extended linear program, like in \thmref{FeasibleBoundedLPVertexOptimalSolution}, \f{\underline{L} \colon \max\{ c^T (x_1 - x_2) \given x_1,x_2 \in \mathbb{R}^n \text{ , } A(x_1 - x_2) \leq b \text{ and } x_1,x_2 \geq 0 \}} with \f{\underline{A} = [A -A; -I 0; 0 -I]}, \f{\underline{c}^T = [c^T -c^T]} and \f{\underline{b} = [b; 0; 0]} which has full rank and we can make the same assumptions as in the first part. We obtain an optimal solution \f{x_1^\star - x_2^\star} and \f{\underline{\lambda} = [\lambda_1 ; \lambda_2; \lambda_3]} which has to respect \f{\underline{\lambda}^T \underline{A} = \underline{c}^T} or \f{\lambda_1^T A - \lambda_2^T = c^T} and \f{\lambda_1^T (-A) - \lambda_3^T = -c^T}. Since \f{\lambda_1, \lambda_2, \lambda_3 \geq 0}, we then have \f{\lambda_1^T A \geq c^T} and \f{-\lambda_1^T A \geq -c^T} or \f{\lambda_1^T A = c^T}. Since \f{\lambda} is dual feasible for the extended program \f{\underline{L}} we have \f{c^T (x_1^\star - x_2^\star) = \underline{\lambda}^T \underline{b} = \lambda_1^T b}, which is what we wanted.

This theorem provides a means to prove optimaly of primal solutions or, equivalently, dual solutions.

If \f{L} is a linear program and \f{\overline{L}} its dual, then \f{\overline{\overline{L}}} is the dual of the dual and it has the same optimum as \f{L}. We have that \f{L \colon \max\{ c^T x \given x \in \mathbb{R}^n \text{ and } Ax \leq b \}} and \f{\overline{L} \colon \min\{ b^T y \given y \in \mathbb{R}^m \text{ , } A^Ty = c \text{ and } y \geq 0 \}}. We can convert \f{\overline{L}} into a program in standard form as \f{\overline{L}' \colon - \max\{ b^T y \given y \in \mathbb{R}^m \text{ , } A^Ty \leq c \text{ , } -A^T \leq -c \text{ and } -y \leq 0 \}} with \f{\overline{A}' = [A^T; -A^T; -I]} and \f{\overline{b}' = [c; -c; 0]}. The dual of this program is \f{\overline{\overline{L}} \colon - \min\{ c^T y_1 - c^T y_2 + 0^Ty_3 \given y_1, y_2, y_3 \in \mathbb{R}^n \text{ , } Ay_1 - Ay_2 - y_3 = -b \text{ and } y_1, y_2 , y_ 3 \leq 0 \}}, which can be transformed into \f{\overline{\overline{L}}' \colon \max\{ c^T (y_2 - y_1) \given y_1,y_2 \in \mathbb{R}^n \text{ , }A(y_2 - y_1) \leq b \text{ and } y_1,y_2 \geq 0 \}} or \f{\overline{\overline{L}}' \colon \max\{ c^T z \given z \in \mathbb{R}^n \text{ and } Az \leq b \}} which is equivalent to \f{\overline{L}}. \def{The dual of the dual is the primal}.

\def{RelationsPrimalDual} \f{L \colon \max\{c^Tx \given x \in \mathbb{R}^n \text{ and } Ax \leq b \}} be a linear program and \f{\overline{L} \colon \min\{b^Ty \given y \in \mathbb{R}^m \text{ , } A^Ty = c \text{ and } y \geq 0 \}} be its dual.
* If \f{L} is feasible and bounded then \f{\overline{L}} is feasible and bounded.
* If \f{L} is feasible and unbounded then \f{\overline{L}} is infeasible.
* If \f{\overline{L}} if feasible and unbounded then \f{L} is infeasible.
* If \f{L} is infeasible then \f{\overline{L}} can be either unbounded or infeasible.
* If \f{\overline{L}} is infeasible then \f{L} can be either unbounded or infeasible.

For part \f{1}, see the first part of the proof of \thmref{StrongDuality}.
For part \f{2}, since \f{L} is unbounded, for all \f{x \in P_L} we can find another \f{x' \in P_L} such that \f{c^Tx \leq c^Tx'}. Also, by \thmref{WeakDuality} we have that for all \f{y \in P_{\overline{L}}} we have \f{c^Tx \leq b^Ty}. But since we can make \f{c^Tx} arbitrarly large, whatever feasible \f{y^\star} we choose, we can produce an \f{x^\star} of larger cost, thus having a contradiction. Therefore \f{\overline{L}} has no feasible solutions and is infeasible. Alternatively, if \f{L} is unbounded and \f{\overline{L}} is feasible and bounded or unbounded then any feasible solution for it is an upper bound for \f{L}, which is a contradiction.
For parts \f{3}, since the dual of the dual is the primal, if the dual is feasible and unbounded then we have that the primal is infeasible, according to part \f{2}.
For parts \f{4} and \f{5}, we have that the infeasibility of the primal can be due to the fact that the dual is unbounded or infeasible, and that the infeasibility of the dual can be due to the fact that the primal is unbounded or infeasible. Consider the following linear program \f{L \colon \max\{ x_2 \given (x_1,x_2) \in \mathbb{R}^n \text{ , } x_1 \leq -1 \text{ and } -x_1 \leq 1 \}}. We have \f{P_L} is \f{\mathbb{R}^2 \setminus \{ (x,y) \given x \in [-1,1] \text{ and } y \in \mathbb{R} \}} which is not feasible, \f{c = [0 -1]} and \f{c \perp a_1 = [1 0]} and \f{c \perp a_2 = [-1 0]}, therefore we can have no \f{y} such that \f{A^T y = c} because \f{[1 0; -1 0] [y_1; y_2] = [0 1]} or \f{[y_1 -y_1] = [0 1]} has no solutions. Therefore, we have an example which sheds light on the complexities of the problematic case.

If you have a solver which produces \f{x^\star} and \f{y^\star} you also have a prood of the optimality of \f{x^\star} by verifying that \f{c^Tx^\star = b^Ty^\star} - this is a polynomial size proof of the optimality.

\def{Farkas' Lemma} \f{Ax \leq b} be a system of inequalities. \f{Ax \leq b} is infeasible iff there exists \f{\lambda > 0 \in \mathbb{R}^m} such that \f{\lambda^TA = 0} and \f{\lambda^Tb = -1}.

For the ``\f{\Rightarrow}'' part, consider the program \f{L \colon \max\{ 0^Tx \given x \in \mathbb{R}^n \text{ and } Ax \leq b \}} with its dual \f{\overline{L} \colon \min\{ b^Ty \given y \in \mathbb{R}^m \text{ , } A^Ty = 0 \text{ and } y \geq 0 \}}. Notice that \f{y^\star = 0} is a feasible solution for \f{\overline{L}}. Therefore \f{\overline{L}} is feasible. But \f{\overline{L}} must also be unbounded, otherwise it would be feasible and bounded and we'd have by \thmref{StrongDuality} and \thmref{RelationsPrimalDual} that \f{L} is feasible and bounded, which is a contradiction. We can therefore find a \f{y^\star \geq 0} with \f{A^Ty^\star = 0} and \f{b^T y^\star < 0}. We build \f{y' = y^\star / \abs{b^Ty^\star}} and notice that \f{A^Ty' = A^Ty^\star / \abs{b^Ty^\star} = 0}  and \f{b^Ty' = b^Ty^\star / \abs{b^Ty^\star} = -1} because \f{b^Ty^\star < 0}. Therefore we have found our \f{\lambda = y'}.
For the ``\f{\Leftarrow}'' part, consider \f{Ax \leq b} and multiply by \f{\lambda^T \geq 0} on each side, which preserves \f{\leq}. We obtain \f{\lambda^T A x \leq \lambda^T b} or \f{(\lambda^T A) x \leq \lambda^T b} or \f{0^T x \leq -1} which is not satisfied by any \f{x}, therefore \f{Ax \leq b} is infeasible.

The linear program \f{\max\{ c^T x \given Ax \leq b \text{ and } x \geq 0 \}} has \f{\min\{ b^T y \given A^T y \geq c \text{ and } y \geq 0 \}} as its dual. The linear program \f{\min\{ c^T x \given Ax \leq b \text{ and } x \leq 0 \}} has \f{\max\{ b^T y \given A^T y \leq c \text{ and } y \geq 0 \}} as its dual. 

