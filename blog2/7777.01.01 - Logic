Logic is one of the oldest intellectual disciplines in human history. It dates back to Aristotle; it has been studied through the centuries; and it is still a subject of active investigation today. We use Logic is just about everything we do. We use it in our personal lives. We use it in our professional activities. We use the language of Logic to state observations, to define concepts, and to formalize theories. We use logical reasoning to derive conclusions from these bits of information. We use logical proofs to convince others of these conclusions. And we are not alone! Logic is increasingly being used by computers - to prove mathematical theorems, to validate engineering designs, to diagnose failures, to encode and analyze laws and regulations and business rules.

Logic is the study of information encoded in the form of logical sentences. We use the language of logic when we state statements, define definitions etc. We use logical reasoning to derive conclusions and convince others of their validity. There is a set of possible worlds. Each sentence partitions the set of worlds into two : one in which the sentence is true and another in which the sentence is false. Given two sentences, we have four partitions, one of which is the one in which both statements are true. Ideally, when we have enough sentences, there is a single world we're talking about. A set of premises (sentences) \def{logically entails} a conclusion if any only if every world that satisfies the premises satisfies the conclusions. Determining entailment by checking all worlds is intractable. The alternative is to use logical reasoning or \def{proofs}. A \def{rule of inference} is a reasoning pattern consisting of some premises and some conclusions. What matters is the form of the pattern, not the content of the premises and some conclusions. [Define soundness and completeness for a rule of inference]. What distinguishes a correct pattern from one that is incorrect is that it must always lead to correct conclusions, i.e. conclusions that are logically entailed by the premises. This is the defining criterion of \def{deduction}. \def{Induction} is reasoning from the particular to the general. If we see enough cases in which something is true and we never see a case in which it is false, we tend to conclude that it is always true. Abduction is reasoning from effects to possible causes. Many things can cause an observed result. We often tend to infer a cause even when our enumeration of possible causes is incomplete. Reasoning by analogy is reasoning in which we infer a conclusion based on similarity of two situations. Of all types of reasoning, deductive reasoning is the only one that guarantees its conclusions in all cases. It has some very special properties and holds a unique place in Logic. We concentrate entirely on deduction and leave these other forms of reasoning to others.

\def{Formal logic} has simple syntax (is easy to read and gramatically unambiguous), has clear semantics (tells us what each sentence says, tells us which conclusions follow from premises) and has precise rules of inference (each rule is sound and complete). This is a parallel to algebra and equational reasoning. \def{Propositional Logic} is the logic of propositions. Symbols in the language represent ``conditions'' in the world, and complex sentences in the language express interrelationships among these conditions. The primary operators are Boolean connectives, such as and, or, and not. \def{Relational Logic} (Herbrand Logic) upon Propositional Logic by providing a means for explicitly talking about individual objects and their interrelationships (not just monolithic conditions). In order to do so, we expand our language to include object constants, function constants, relation constants, variables, and quantifiers. \def{First Order Logic} (Epistemic Logic) is a variant of Herbrand Logic that provides greater flexibility in encoding information. First Order Logic supports synonyms and unnamed objects and allows one to define abstract concepts, which apply across worlds of different size. Each logic brings new issues and capabilities to light. Despite these differences, there are many commonalities among these logics: there is a language with a formal syntax and a precise semantics; there is a notion of logical entailment; and there are legal rules for manipulating expressions in the language. 

We're using logic to study logic. This can lead to some confusion. We will have proofs, which are logical objects we study, and meta-proofs, which are demonstrations of certain facts about the objects we're working with (logics, proofs, certain algorithms etc.).

= Propositional Logic =

A mathematical model that allows us to reason about the truth of falsehood of logical expressions. A logical expression is: basis/atomic operands - prepositional variables and the logical constants TRUE or FALSE or, if \f{E} and \f{F} are logical expression, then so are \f{E \land F} (value is TRUE if both \f{E} and \f{F} are true, associative, commutative), \f{E \lor F} (value is TRUE if either \f{E} or \f{F} is true, associative, commutative), \f{\lnot E} (value is TRUE if \f{E} is FALSE). A prepositional variable is a symbol which stands for any other expression which might take the values of TRUE and FALSE, just like with arithmetic, set, relational, and regular expressions (algebras). Parantheses can be used for grouping, but, \f{\land} and \f{\lor} are left associative (no matter though since they are associative) the order of precedence is \f{\lnot, \land, \lor}.

\f{\land} is also reffered to as product or conjunction. \f{\lor} is also reffered to as sum or disjunction. We could write logical expressions by replacing \f{\land} by catenation and \f{\lor} by sum, just like in arithmetic expressions. Similarly, an overbar for \f{\lnot} does the trick.

Truth assignment: a function which maps every variable to either TRUE or FALSE.

Evaluate a logical expression: a procedure of obtaining the value of a given logical expression, assuming a certain assignment. \f{E[TRUE,f] = TRUE}, \f{E[FALSE,f] = FALSE}, \f{E[q, f] = f(q)}, \f{E[F_1 \land F_2, f] = TRUE} if \f{E[F_1, f] = TRUE} and \f{E[F_2, f] = TRUE}, otherwise \f{FALSE}, \f{E[F_1 \lor F_2, f] = TRUE} if \f{E[F_1, f] = TRUE} or \f{E[F_2, f] =TRUE}, otherwise \f{FALSE}, \f{E[\not F_1] = TRUE} if \f{E[F_1, f] = FALSE}, otherwise \f{FALSE}, where \f{f} is the assignment function. This is the same kind of expression evaluation as for other algebras. A logical expression's meaning is a function that takes truth assignments and returns either TRUE or FALSE - a Boolean function (tuples of assignments and TRUE / FALSE outputs).

Truth table: representation of a logical expression with all possible values for its variables. If there are \f{k} variables the table has \f{k+1} columns ans \f{2^k} rows (number of assignments of \f{2} values to \f{k} bins, with replacement). While a truth table is finite, its exponentially growing size often forces us to find other means to understand, evaluare, or compare Boolean functions. The number of Boolean functions of \f{k} variables is \f{2^{2^k}} (such a function can be described by \f{2^k} values, if we keep the trutu table in a known, ascending order, and this is the assignment problem with \f{2^k} bins and \f{2} values again).

Other useful Boolean operators:
* Implication: \f{p \rightarrow q}, which means "if \f{p} is TRUE, then \f{q} is TRUE, which is FALSE when \f{p} is TRUE and \f{q} is FALSE (TRUE does not imply FALSE, TRUE implies TRUE, but FALSE implies both TRUE and FALSE). Not associative, not commutative.
* Equivalence: \f{p \equiv q}, which is true when both \f{p} and \f{q} are TRUE or both \f{p} and \f{q} are FALSE, otherwise it is FALSE. Associative, commutative.
* NAND: not-and. We have \f{p \text{NAND} q \equiv \lnot (p \land q)}. Not associative, commutative.
* NOR: not-or. We have \f{p \text{NOR} q \equiv \lnot (p \lor q)}. Not associative, commutative.
 \f{k}-ary versions of \f{\land} and \f{\lor}, defined naturally since the operators are associative.
* \f{NAND} and \f{NOR}, defined as \f{\lnot} of the \f{\land} or \f{\lor} of the arguments, since \f{NAND} and \f{NOR} are not associative.
* \f{\lxor}, which is TRUE if either \f{p} is TRUE or \f{q} is TRUE, but not both, otherwise it is FALSE. It is associative, commutative.

Full precedence order is: \f{\lnot}, \f{NAND}, \f{NOR}, \f{\land}, \f{\lor}, \f{\rightarrow}, \f{\equiv}. \f{NAND} and \f{NOR} are left-associative in expressions, but we generally use parantheses.

Similarities with set theory: \f{\lor} acts like set union, \f{\land} like set intersection and \f{\lnot} as set complement. There is a natural correspondence between the \f{2^k} rows of a truth table for the expression and the \f{2^k} regions of a Venn diagram for the equivalent set expression. More precisely, every region can be binary coded with a \f{k}-bit vector which is \f{1} in position \f{j} if that region contains elements from set \f{j}, otherwise \f{0}. A logical expression determines a number of these \f{2^k} sets, which are all the sets for which the corresponding code word is \f{1} through the expression.

An expression \f{F} does not depend on variable \f{i}, if, for all values of the other variables \f{\hcrange{1}{k}\setminus\{i\}} we have \f{F(x_1,\dots,x_{i-1},TRUE,x_{i+1},\dots,x_k) = F(x_1,\dots,x_{i-1},FALSE,x_{i+1},\dots,x_k)}. We can reduce the function to a \f{k-1} variable one, in this case, as supplying either TRUE or FALSE for \f{x_i} does not alter the answer.

Given a truth table, we wish to build the corresponding logical expression, using a set of operators. The expression should be the simplest one possible.

Disjunctive normal form: consider a literal as either a variable or the negation of a variable (either \f{p} or \f{\overline{p}}). A minterm for \f{k} variables with values \f{x_1,\dots,x_k} is a conjunction of \f{k} literals, each corresponding to one of the variables. If \f{x_i} is \f{1} then we include the positive literal, otherwise we include the negative literal. The minterm is a boolean function which has value \f{1} only for input \f{x_1,\dots,x_k} (if we feed \f{0} for \f{p_i} when \f{x_i=1}, then the literal will be \f{p_i}, and it will have value \f{0}, causing the whole minterm to be \f{0}). Therefore a minterm is a very specific selector function. Given the truth table for a function, we can look at all the rows which have \f{1} as their value, and build a minterm for each. Then, a final expression \f{m_1 + m_2 + \dots + m_n} will be \f{1} whenever one of the minterms is \f{1}. But, given a set of values with output \f{1}, only one minterm can be active (by definition, because each term corresponds to a given row, and is activated only by that row) and it determines the whole expression to be active. If the given set is \f{0}, then no minterm is activated, therefore the expression is \f{0}. This is then an expression for the truth table, called the disjnunctive normal form. Each min-term has \f{k} literals and at most \f{2k-1} operators. However, there can be \f{O(2^k)} min-terms (consider the constant \f{1} function), therefore the expression is exponential in size in the worst-case.

Conjunctive normal form: consider a literal as either a variable or the negation of a variable (either \f{p} or \f{\overline{p}}). A maxterm for \f{k} variables with values \f{x_1,\dots,x_k} is a disjunction of \f{k} literals, each corresponding to one of the variables. If \f{x_i} is \f{1} then we include the negative literal, otherwise we include the positive literal. The maxterm is a boolean function which has value \f{0} only for input \f{x_1,\dots,x_k} (if we feed \f{1} for \f{p_i} when \f{x_i=0}, then the literal will be \f{p_i}, and it will have value \f{1}, causing the whole maxterm to be \f{1}). Therefore a maxterm is a very specific selector function. Given the truth table for a function, we can look at all the rows which have \f{0} as their value, and build a maxterm for each. Then, a final expression \f{m_1m_2\cdots m_n} will be \f{0} whenever one of the maxterms is \f{0}. But, give a set of values with output \f{0}, only one maxterm can be active (by definition, because each term corresponds to a given row, and is activated (set to \f{0}) only by that row), all the others are \f{1}, and it determaxes the whole expression to go to \f{0}. If the given set is \f{1}, then no maxterm is activated (the maxterms are activated only by a single row), therefore the expression is \f{1}. This is then an expression for the truth table, called the conjunctive normal form. Each maxterm has \f{k} literals and at most \f{2k-1} operators. However, there can be \f{O(2^k)} maxterms (consider the constant \f{0} function), therefore the expression is exponential in size in worst-case.

DNF and CNF show that \f{\land}, \f{\lor} and \f{\lnot} can express any boolean function, therefore they are a complete set. NAND is another function which forms a complete set all by itself (we can express the previous three functions in terms of NAND as \f{p \land q \equiv ((p NAND q) NAND TRUE)}, \f{p \lor q \equiv ((p NAND TRUE) NAND (q NAND TRUE))} and \f{\lnot p \equiv (p NAND TRUE)}). \f{\land} and \f{\lor} are not complete because they are monotone and any expression with them is monotone as well (by induction), whereas \f{\lnot} (a valid boolean function) is not monotone.

An implicant for a Boolean function \f{f} is a product \f{x} of literals for which no assignment of values to the variables of \f{f} makes \f{x} true and \f{f} false, that is,the implicant is true for a subset of the assignments for which \f{f} is true, and no others. If \f{s} is an implicant than \f{s \rightarrow f} is always true. Minterms are implicants. An implicant covers the subset of assignments for which it has truth value. A boolean function can be turned into an expression by taking the \f{\lor} of a set of implicants which cover all assignments where the function is true. By the definition of the implicant, this means that no cases where \f{f} is FALSE but the expression is TRUE arise. If we can find them, implicants can provide much more compact expressions. A prime implicant is an implicant that ceases to be one if any literal is removed. A smallest implicant. An anti-implicant for a Boolean function \f{f} is a sum \f{x} of literals for which no assignment of values to the variables of \f{f} makes \f{x} false and \f{f} true, that is, the anti-implicant is false for a subset of the assignmnets for which \f{f} is true, and no others. Maxterms are anti-implicants.

Karnaugh Maps: good for functions with up to four variables. For two variables we draw a \f{\hctimes{2}{2}} table with one varible as the row, the other as the column and values of the function in the cells. Implicants look like single cells (turned into a minterm), rows or columns (literal corresponding to the common value (we have \f{pq + \overline{p}q \equiv q})) or the entire map (turns into TRUE or FALSE). For three variables we draw a \f{\hctimes{2}{4}} table with one variable as the row and two variables as the columns, but labels ordered in a Gray code, and values of the function in the cells. Implicants look like single cells (turned into a minterm), \f{2}-cell rows or columns (eliminates variable which has both TRUE and FALSE - must be only one because of the Gray codes), \f{4}-cell rows (eliminates both variables on the horizontal), \f{\hctimes{2}{2}} cells (eliminate variables with both TRUE and FALSE) and the entier map (turns into either TRUE or FALSE). For four variables we draw a \f{\hctimes{4}{4}} table with two variables as the row and two variables as the columns, but labels ordered in a Gray code, and values of the function in the cells. Implicants must be rectangular and contain \f{2^i} elements. Both the three and four variable case view the map as a doughnut/torus/maybe sphere (like in Civ). We should seek to use prime implicants (select regions as large as possible) in order to obtain the smallest expressions. One can also use anti-implicants, and make conjunction of disjunction expressions. The same coding as for maxterms applies.

Tautology: a logical expression which is true for all assignments. Tautologies remain tautologies if we consistently replace variables with other expressions (the substitution principle - regardless of the values of the new expression it will still hold, as the tautology holds for the TRUE and FALSE of the replaced value) (if we're not consistent it is as if we're introducting new variables - we have a new expression and it may not be a tautology). To test whether an expression is a tautology, the naive algorithm is \f{O(2^n)}, and it is the best since the problem is is NP-Hard.

Algebraic rules of logical expressions: we will give many of them in the form of equivalence tautologies of the form \f{E_1 \equiv E_2}, which means that we can replace \f{E_1} with \f{E_2} in other expressions.
* Equivalence: reflexivity (\f{p \equiv p}), commutative law \f{(p \equiv q) \equiv (q \equiv p)}, transitive law \f{((p \equiv q) AND (q \equiv r)) \rightarrow (p \equiv r)}, equivalence of negations (\f{(p \equiv q) \equiv (\overline{p} \equiv \overline{q})}).
* Arithmetical looking: commutativity of \f{\land} (\f{pq \equiv qp}), associativity of \f{\land} (\f{p(qr) \equiv (pq)r}), commutative \f{\lor} (\f{p + q \equiv q + p}), associativity of \f{\lor} (\f{p + (q + r) \equiv (p + q) + r}), distributive law for \f{\land} and \f{\lor} (\f{p(q + r) = pq + pr}), TRUE is identity for \f{\land}, FALSE is identity for \f{\lor}, FALSE is anihilator for \f{\land}, double negation (\f{\not\not p = p}).
* Boolean algebra specific: distributive law for \f{\lor} over \f{\land} (\f{p + qr \equiv (p + q)(p + r)}), TRUE is the anihilator of \f{\lor}, idempotence of \f{\land} (\f{pp \equiv p}), idempotence of \f{\lor} (\f{p + p \equiv p}), subsumption of sum (\f{p + pq \equiv p} (in a disjunction we can remove a conjunctive term which is a superset of another conjunctive term, because its value will always be determined by the subset) and \f{p(p + q) \equiv  p} (in a conjunction we can remove a disjunctive term which is a superset of another disjunctive ter, because its value will always be determined  by the subset)), elimination of certain negations (\f{p(\overline{p} + q) \equiv pq} and \f{p + \overline{p}q \equiv p + q}).
* DeMorgan's Laws: \f{\overline{pq} = \overline{p} + \overline{q}} and \f{\overline{p + q} = \overline{p}\overline{q}} and generalizations.
* Implications: \f{(p \rightarrow q) \land (q \rightarrow  p) \equiv (p \equiv q)}, \f{p \equiv q \rightarrow (p \rightarrow q)}, \f{(p \rightarrow q) \land (q \rightarrow r) \rightarrow (p \rightarrow r)}, \f{p \rightarrow q \equiv \overline{p} \lor q} and \f{p_1p_2\cdots p_n \rightarrow q \equiv (\overline{p_1} + \dots + \overline{p_n} + q}.

Propositional Logic deals with propositions and their interrelationships. The notion of a proposition is not defined precisely, but it is roughly a statement of the world which might be true or false. We have simple sentences (express simple facts about the world) and componund sentences (expres logical relationship between other sentences). Simple sentences take the form of atomic symbols, called \def{propositional constants}. These are written as strings of letters, digits and ``\_'', starting with a lowercase letter. Examples: raining, rainingR, raining1, raining\_now. Compound sentences take one of the following six forms: negations (\f{(\lnot p)} where \f{p} is a sentence and is called the \def{target}), conjunctions (\f{(p \land q)} where \f{p} and \f{q} are sentences and are called the \def{conjuncts}), disjunctions (\f{(p \lor q)} where \f{p} and \f{q} are sentences and are called the \def{disjuncts}), implications (\f{(p \Rightarrow q)} where \f{p} and \f{q} are sentences, \f{p} is called the \def{antecedent} and \f{q} is called the \def{consequent}), reductions (\f{(p \Leftarrow q)} where \f{p} and \f{q} are sentences, \f{p} is called the \def{consequent} and \f{q} is called the \def{antecedent}) and equivalences (\f{(p \Leftrightarrow q)}, where \f{p} and \f{q} are sentences). Operators have \def{precedence}. Their odrer is \f{\neg}, \f{\land}, \f{\lor} and \f{\Rightarrow}, \f{\Leftarrow} and \f{\Leftrightarrow} (all three at the same level). We can drop the parantheses from our expressions, because the precedence rules make sentences unambiguous. The precedence rule \f{1}: an operand surrounded by two operators associates with the operator of higher precedence. The precedence rule \f{2}: an operand surrounded by two operators of equal precedence associated with the operator on the right side.

A \def{propositional vocabulary} is a set of proposition constants. A \def{propositional sentence} is either an individual proposition constant from the vocabulary, or a compound sentence formed from simpler propositional sentences. A \def{propositional language} is the set of all propositional sentences that can be formed from a propositional vocabulary.

A \def{propositional truth assignment} is an association between the propositional constants in a propositional language and the truth values \def{true} (\f{1}) and \def{false} (\f{0}). If \f{i} is such an assignment we use \f{p^i = 1} to denoted that the prepositional constant \f{p} is assigned a value of \f{1} (true) by \f{i}. If we have \f{n} constants in a prepositional vocabulary, we have \f{2^n} possible assignments. These are not themselves sentences in propositional logic (as it does not allow superscripts or the equals sign). These are informal meta-level statements about particular truth assignments. A \def{sentential truth assignment} is an association between arbitrary sentences in a propositional language and the truth values \f{1} and \f{0}. These are not arbitrary however. Given a propositional truth assignment, the operator semantics of propositional logic assign each sentence a particular value.

Operator semantics are given in ``truth tables''. These say what the truth assignment of a compound sentence, in terms of the truth values of the simpler sentences. Table \ref{eq:TruthTables} shows the truth assignments for \f{\lnot}, \f{\land}, \f{\lor}, \f{\Rightarrow}, \f{\Leftarrow} and \f{\Leftrightarrow}. \f{\lor} is an \def{inclusive or} - the disjunction is true if and only if at least one of its disjuncts is true. \f{p \lxor q} is the \def{exlusive or} - the disjunction is true if and only if exactly one of its disjuncts is true. The semantics of implication here is called \def{material implication}. Any implication is true if the antecendet is false, wheter or not there is a connection to the consequent. However, if the antecedent is true, then the consequent must be true, in order for the whole sentence to be true. Intuitively, if the antecedent is false, the implication tells us nothing about the consequent. These sentences are called \def{counterfactuals}.

%formula{
\begin{array}{|c|c||c|c|c|c|c|c|}
\hline
p & q & \lnot{}p & p\land{}q & p\lor{}q & p\Rightarrow{}q & p\Leftarrow{}q & p\Leftrightarrow{}q \\
\hline
0 & 0 & 1 & 0 & 0 & 1 & 1 & 1 \\
0 & 1 & 1 & 0 & 1 & 1 & 0 & 0 \\
1 & 0 & 0 & 0 & 1 & 0 & 1 & 0 \\
1 & 1 & 0 & 1 & 1 & 1 & 1 & 1 \\
\hline
\end{array}
}

The \def{evaluation problem}: given a propositional truth assignment and a sentence, find the truth value of the sentence under the assignment.

The \def{evaluation procedure}: start with a propositional truth assignment and a sentence. Replace proposition constants by their truth values and use operator semantics to simplyfi compound sentences with truth values as arguments. Repeat this inside-out fashion to produce a value for the sentence as a whole. The algorithm is \f{O(k)} in the size of \f{k} of the sentence.

A truth assignment \def{satisifies} a sentence if and only if it assignes the value \f{1} to the sentence. A truth assignment \def{satifies} a set of sentences if and only if it satisfies each sentence in the set. A truth assignment \def{falsifies} a sentence if and only if it assigns the value \f{0} to the sentence. A truth assignment \def{falsifies} a set of sentence if and only if it falsifies at least one sentence in the set.

The \def{satisfaction problem}: given a set of sentences and a sentential truth assignment for them, find a prepositional truth assignment which leads to the sentential truth assignment. This is the inverse problem of the evaluation problem.

The \def{truth table procedure} for the satisfaction problem: build the \f{2^n} truth table for the \f{n} proposition constants in our sentences and add \f{k} columns for the \f{k} sentences in the set. Evaluat each sentence for each of the rows of the truth table. Any row that satisfies all sentences in the set is a solution to the problem.

A sentence is \def{valid} if and only if every interpretation (propositional truth assignment) satisfies it. A sentence if \def{unsatifiable} if and only if no interpretation satifies it (every interpretation falsifies it). A sentence is \def{contingent} if and only if some interprettions satify it and the other interpretations falsify it. A sentence is \def{satisfiable} if and only if it is either valid or contingent. A sentence is \def{falsifiable} if and only if it is contingent or unsatisfiable.

In one sense, valid sentences and unsatisfiable sentences are useless. Valid sentences do not rule out any possible truth assignments; unsatisfiable sentences rule out all truth assignments; thus they say nothing about the world. On the other hand, from a logical perspective, they are extremely useful in that, as we shall see, they serve as the basis for legal transformations that we can perform on other logical sentences.

Let \f{\mathcal{V}} a set of propositional constants. Then
* \f{p \lequiv \lnot\lnot p} - double negation.
* \f{\lnot (p \land q) \lequiv (\lnot p \lor \lnot q)} - deMorgan's Law \f{\#1}.
* \f{\lnot (p \lor q) \lequiv (\lnot p \land \lnot q)} - deMorgan's Law \f{\#1}.
* \f{p \limply (q \limply p)} - implication introduction.
* \f{(p \limply (q \limply r)) \limply ((p \limply q) \limply (p \limply r))} - implication distribution.

We are interested in the relative properties of sentences, not necesarily the properties of sentences.

A set of premises \f{\Delta} \def{logically entails} a conclusion \f{\Phi}, denoted by \f{\Delta \lentail \Phi}, if and only if every interpretation that satisfies the premises also satisfies the conclusion. Logical entailment is different from logical equivalence, and is, in a sense, similar to arithmetic inequality, rather than equality.

The \def{entailment problem}: given a set of premises \f{\Delta} and a conclusion \f{\Phi}, determine wheter \f{\Delta \lentail \Phi}.

The \def{truth table procedure} for the entailment problem: form a truth table fro the proposition constants and add a column for each premise and a column for the conclusion. Evaluate the premises for each row in the table. Evaluate the conclusion for each row in the table. If every row that satisfies the premises also satisfies the conclusion, then the premises logically entail the conclusion.

Let \f{\Delta} be a set of sentences and \f{\Phi} a sentence. Then \f{\Delta \lentail \Phi} if and only if \f{\Delta \cup \{\lnot \Phi\}} is unsatifiable. A set of sentences \f{\Delta} entails a the sentence \f{\Phi} if there isn't any truth assignment which makes \f{\Delta \cup \{ \lnot \Phi \}} satifiable, or \f{\lnot Phi} is not satisfiable in any truth assignment which make \f{\Delta} satisfiable. We can determine logical entailment by determining unsatisfiability.

For ``\f{\limply}'': If a truth assignment \f{i} satifies \f{\Delta}, then it must also satisfy \f{\Phi}. But then, it cannot satisfy \f{\lnot \Phi}. Therefore \f{\Delta \cup \{ \lnot \Phi \}} is unsatisfiable.
For ``\f{\lreduce}'': Every truth assignment that satisfies \f{\Delta} must fail to satisfy \f{\lnot \Phi}, and must satisfy \f{\Phi}. Therefore, \f{\Delta \lentail \Phi}.

The truth table procedure does not scale (at all). It has time complexity \f{O(2^n)}. An alternative are \def{proofs} - the symbolic manipulation of sentences, rather than the enumeration of truth assignments. Proofs are usually smaller than truth tables and can often be found with less work.

A \def{schema} is an expression safisfying the grammatical rules of our logical language except for the occurance of metavariables (usually written as GReek letters) in place of various subparts of the experssion. An \def{rule of inference} is a pattern of reasoning of consisting of some schemas, called \def{premises}, and one or more additional schemas, called \def{conclusions}. These are written as a list of premises, a horizontal line and a list of conclusions. A common rules of inference is Implication Elimination.

%formula{
\inferrule{\phi \Rightarrow \psi \\\\ \phi}{\psi}
}

An \def{instance} of a rule of inference is a rule in which all metavariables have been consistently replaced by legal sentences. A rule \def{applies} to a set of sentences if and only if there is an instance of the rule in which all of the premises are in the set. The conclusions of the instance are the \def{results} of the rule application. An \def{axiom schema} is a rule of inference without premises. These are written without horizontal lines. We can derive any instance we want. Some common axiom schemata are:
* \f{\phi \Rightarrow (\psi \Rightarrow \phi)} - Implication Creation.
* \f{(\phi \Rightarrow (\psi \Rightarrow \chi) \Rightarrow ((\phi \Rightarrow \psi) \Rightarrow (\phi \Rightarrow \chi))} - Implication Distribution.
* \f{(\phi \Rightarrow \psi) \Rightarrow ((\phi \Rightarrow \lnot \psi) \Rightarrow \lnot \phi)} - Contradiction Realization.

A \def{linear proof} of a conclusion from a set of premises is a sequence of sentences terminating in the conclusion in which each item is either a premise, an instance of an axiom schema or the result of applying a rule of inference to earlier items in sequence.

An \def{proof system} is a collection of rules of inference. A conclusion is said to be \def{provable} from a set of premises using a proof system R if there is a finite proof of the conclusion from the premises using only the rules in R. We write \f{\Delta \lentail_R \phi} to express this fact.

The \def{Mendelson System} is a proof system which uses the Implication Elimination / Modus Poens rule of inference and the Implication Creation, Implication Distribution and Conflict Realization axiom schemata. It is sufficient to prove logically entailed conclusions where premises and conclusions are written using only \f{\lnot} and \f{\Rightarrow} (and any sentence in propositional logic can be rewritten to be such a sentence).

We can use \def{structured proofs} to bring even more power. In a structured proof, it is permissible to make an arbitrary assumption in any nested proof. This must not be a member of the premises set. It is not permissible to use sentences in subproofs of that subproof or in other subproofs of its superproofs.

A \def{structured rule of inference} is a pattern of reasoning consisting of one or more schemas, called \def{premises}, and one or more additional schemas, called \def{conclusions}, in w hich at least one of the premises is a condition of the form \f{\phi \lentail \psi}. An example is the rule called \def{Implication Introduction}:

%formula{
\inferrule{\phi \lentail \psi}{\phi \Rightarrow \psi}
}

That is, if we can ``prove'' that \f{\phi} entails \f{\psi} we have that \f{\phi} implies \f{\psi}.

A structured rule \def{applies} to a particular subproof of a structured proof iff there is an instance of the rule in which all of the premises are satisfied. A premise that is a simple schema is satisfied iff the premise occurs earlier in the subproof or in some superproof of the subproof. A premise of the form \f{\phi \lentail \psi} is satisfied iff there is an eralier subproof withing the current subproof where \f{\phi} is the only premise and \f{\psi} is any conclusion.

The \def{Fitch system} is a structured proof system, with \f{10} rules of inference. [show rules]

A proof system \f{R} is \def{sound} iff every probable conclusion is logically entailed. \f{\Delta \lentail_R \phi} implies \f{\Delta \lentail \phi}.

A proof system \f{R} is \def{complete} iff every logically entailed conclusion is provable. \f{\Delta \lentail \phi} implies \f{\Delta \lentail_R \phi}.

The Mendelson System is sound and complete for all premises and conclusions that can be written in terms of \f{\lnot} and \f{\Rightarrow}. The Fitch System is sound and complete for the entire language of Propositional Logic. The truth table method and the proof method succed in exactly the same cases. The proofs are much smaller.

== Methods Of Proof ==

Methods of Proof: all these methods follow simply from the previous properties of logic. Logic serves as a formalization of proof techniques.

Law of Excluded Middle: a proposition is either true or false - there is no middle ground. Then \f{p + \overline{p} \equiv 1} is a tautology.

Case Analysis: in the simplest case, prove that both a proposition and its negation imply another proposition. Then \f{(p \rightarrow q) \land (\overline{p} \rightarrow q) \equiv q} is a tautology.

Only One: a proposition can be true or false, but not both. Then \f{p\overline{p} \equiv 0} is a tautology.

The contrapositive of implication \f{p \rightarrow q} is \f{\overline{q} \rightarrow \overline{p}}. A proof by contrapositive requires us to prove the contrapositive in order to prove the direct version. \f{p \rightarrow q \equiv \overline{q} \rightarrow \overline{p}} is a tautology. If a statement implies another statement, then if the second statement is false, the first one cannot be true.

Contradiction: it is sometimes easier to prove that a statement is true, by assuming it is false, and reaching a contradiction - the expression FALSE. Then \f{\overline{p} \rightarrow 0 \equiv p} is a tautology. If we have that the negation of \f{p} implies false is true, it means that the negation of \f{p} is FALSE (since truth does not imply false). Then since \f{\overline{p} \equiv FALSE} we have \f{p \equiv TRUE}.

Equivalence to Truth: simply perform substitutions of expressions until we reach TRUE. Then \f{(p \equiv 1) \equiv p}.

Deduction: starting from a set of hypothesies and using a set of inference rules, reach a conclusion. Hypotheses and conclusions are written in the language of logic. Inference rules are written in terms of logical statements, but are at a higher-level (even though they might mimick logical statements). In general, deduction is NP-Hard, but we have nice heuristics. We start with \f{E_1,\dots,E_k} and want to reach \f{E}. That is \f{E_1 \land E_2 \land \cdots \land E_k \rightarrow E} is a tautology. For propositional logic, the tautology test works, but is impratical. Deduction consists of building a proof using the inference rules, as a sequence of steps / transformation of the start hypotheses and any intermediary obtained ones, until we reach \f{E} and it can sometimes be much faster (humans usually use it, no?). More complex logics only have deduction, for example.
* The process starts with \f{T} - the set of TRUE propositions as \f{T = \{E_1,\dots,E_k\}}. At each step we add one new proposition to \f{T}, until we find \f{E}. All statements in \f{T} at a certain step are true, simultaneously, since the deductive process assumes it. Therefore, all inference rules are basically used assuming \f{\land_{t \in T} t \equiv TRUE}.
* Inference rules: an inference rules has some requirements, expressed as needing certain statements of certain forms to be in \f{T} (elements before the line) and produces certain results, that is, certain statements that will be introduced into \f{T} upon its application.* Introducing tautologies: if \f{F} is a tautology, then we can simply introduce it into \f{T}. No elements before the line. \f{F} will usually replace generic variables with expression in \f{T} though.
* Making conjunction of terms explicit: if \f{A} and \f{B} are before the line, then \f{AB} is after the line. This follows from the assumption that \f{T} contains only true statements / tautologies.
* Modus Poens: if \f{A} and \f{A \rightarrow B} are before the line, then \f{B} is after the line. Intuitively true, by the tautology \f{A \land (A \rightarrow B) \equiv B}.
* Equivalence: if \f{A} and \f{A \equiv B} are before the line, then \f{B} is after the line. Intuitively true, by the tautology \f{A \land (A \equiv B) \equiv B}, a stronger case of Modus Poens.

= Predicate Logic =

An extension and more powerful version of propositional logic. A predicate is a function of several arguments, which takes on value TRUE or FALSE. A logical expression is: an atomic formula is a predicate with zero or more arguments. An argument is either a constant or a variable (which can be numbers, strings etc.). Variables are symbols capable of taking on any constant as value. They are different from propositional variables, which correspond to zero-argument predicates. An atomic formula whose arguments are all constants is a ground formula. A proposition is a ground formula. A literal is either an atomic formula or its negation. A ground literal is one where the formula is a ground formula. In general, when in propositional logic we spoke of variables, here we speak of formulas. Literals then have the same definition in both situations. We can also form expressions in CNF or DNF. A logical expression is formed from literals joined by the logical operators of propositional logic, and by quantifiers.

There exists / existential quantifier: the operator \f{(\exists X)(E(X))}, where \f{E} is another logical expression. Informally, the new expression is true if at least one value for \f{X} can make \f{E} true. More precisely, for every value of \f{E}'s other variables, we can find a value of \f{X} such that \f{E} is true. It is a sort of infinite \f{\lor}.

For all / universal quantifier: the operator \f{(\forall X)(E(X))}, where \f{E} is another logical expression. Informally, the new expression is true if all values for \f{X} can make \f{E} true. More precisely, for every value of \f{E}'s other variables, and all values of \f{X} \f{E} is true. It is a sort of infinite \f{\land}.

The same precedence rules apply as for propositional logic. The quantifiers have the highest level of precedence. The parantheses around \f{\exists} and \f{\forall} are part of the syntax, however. The order of the quantifiers MATTERS. Do not change it.

Bound/free variables: in an expression \f{E} we have refernces to a variable \f{X}. In general, \f{X} will be bound to the closest quantifier going up the expression tree from it. Bounded will mean that, in the relations which make use of the variable, we actually will refer to whatever value(s) the quantifier selects for us. Other expressions with other quantifiers can also bound \f{X}, and that is a different \f{X} from the one in \f{E} (even if they are ancestors in the expression tree). A variable which is not bound is free. We can bound all free variables by extending the expression \f{E} as such: if \f{X_1,\dots,X_l} are free variables, then the equivalent is \f{(\forall X_1) (\forall X_2) \dots (\forall X_l) E}. Variables are just names for objects, and bound/free reflects this. We could rename each variable to a unique name, according to the quantifier who binds it etc.

The domain is a set \f{D} of values, from which we select values for the variables. It must also contain all constants which appear in our expression.

The interpretation of a predicate \f{p} with \f{k} arguments is a function of \f{k} arguments which maps from \f{D^k} to \f{\{TRUE,FALSE\}}. It tells us, for each combination of variables, taken from the domain, whether the function is true or false.

The interpretation of an expression consists of \f{D}, an interpretation for each predicate and a value in \f{D} for each free variable of the expression. It is akin to the truth assignment in propositional logic.

The meaning of an expression is a function that takes an interpretation and return \f{0} or \f{1}. The interpretation is all that we need about the formulas and variables of an expression in order to evaluate it to \f{0} or \f{1}. We can formally define meaning, as for propositional logic, by a structural induction on the expression tree for a given logical expression \f{E}. The basis case (a leaf) refers to an atomic formula, with arguments free variables or constants, for which the interpretation gives values, and an interpretation for the predicate in the atomic formula. In general, for a given expression with an operator as the root, we have an operator. If the operator is \f{\land}, \f{\lor}, \f{\lnot} etc. then the we find the meaning of the subexpressions (which we can do, by the inductive hypothesis) and combine the results according to the operator. If we have \f{(\exists X) E_1}. We build a set of interpretations \f{I_v = I \cup \{X = v\}} - our interpretation (which can evaluate \f{E_1}) and assigning value \f{v} to \f{X} (which might or might not appear in \f{E_1}). If there is one such interpretation which makes \f{E_1} true, then the whole expression is true. Otherwise it is false. We do a similar thing for the \f{\forall} operator, but all interpretations must give an answer.

Tautology: an expression which is true for every interpretation. The tautologies of propositional logic are a good source of tautologies in predicate logic. The substitution principle holds for the same reasons as it does in propositional logic. Two expressions are equivalent if \f{E_1 \equiv E_2} is a tautology. We can then replace one expression with another, in any circumstance.

A tautology can be transformed in a form with no free variables. Simply universaly quantify the free variable.

Closed expression: one without any free variables.

Pushing \f{\lnot} through quantifiers: \f{\lnot (\exists X) E \equiv (\forall X) \lnot E} and \f{\lnot (\forall X) E \equiv (\exists X) \lnot E} are tautologies. The meaning is intuitive (if it is true that no \f{X} exists which makes \f{E} true then all \f{X} make \f{E} false etc.). Viewing quantifiers as infinite ors and ands and applying DeMorgan's law also helps.

Pushing \f{\land} and \f{\lor} through quantifiers: \f{E \land (QX) F \equiv (QX) (E \land F)} and \f{E \lor (QX) F \equiv (QX) (E \lor F)} where \f{X} is not free in \f{E}.

Prenex form: an expression form with unique identifiers for all quantifiers, and all quantifiers as the top levels of the tree. We can do this by doing variable ranaming (in the safe way presented here, not overwriting any free variales for other expressions) and pushing throw \f{\lnot}, \f{\land} and \f{\lor}. Since the operators form a closed set, we can express any expression in prenex form.

Reordering quantifiers: \f{(\forall X)(\forall Y) E \equiv (\forall Y) (\forall X) E} and \f{(\exists X) (\exists Y) E \equiv (\exists Y) (\exists X) E}. This is a sort of commutative law for the quantifiers.

Model: the set of interpretations that make an expression true.
