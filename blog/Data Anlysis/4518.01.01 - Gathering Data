define {Experiment}

define {Survey}


Data are defined by how they are collected. We have
\vspace{-0.6em}
\begin{enumerate}
\itemsep0em
\item Census for descriptive analysis. Each object/individual is measured. We don't need to do inference, since we have access to the whole population and can compute what we want from it.
\item Observational study for inferential analysis. A random sample without replacement is selected from the population and measured. Using the data about them we make inference about the population.
\item Convenience sample for all types, but has a bias. Samples which contain measurements for objects which are ``easier'' to obtain. Care should be taken when performing inference or prediction.
\item Randomized trial for causal analysis. Want to find a variable that, when changed, leads to a change in another variable (Medical treatment experiments). We introduce the change, independent of the other variables, and see what happens.
\item Prediction study for prediction. We build a prediction model on a training sample. We apply the prediction mode on a test sample, in order to evaluate how good it is.
\item Cross-sectional study over time for inferential analysis. Picks a particular time-point of a population and performs a random sampling.
\item Longitudinal study over time for inferential and predictive analysis. Follow individuals at each time step.
\item Retrospective for inferential analysis. Follow individuals over time, but we randomly sample them just at the end, and we measure their outcomes (?? and ask them about their evolution ??).
\end{enumerate}
\vspace{-0.6em}

The elements of a study: two or more groups, a \emph{response variable} (or \emph{outcome}) to be computed between the groups, one or more \emph{explanatory variables} which are variables that can be used to possibly explain the differences in the response variable between the groups. There are also \emph{confounding variables}, which differ between the group and may affect the response variable so we can't tell what causes the differences between the groups - we need to collect data carefully in order to avoid confounding!

Data collection methods: \emph{anecdotes} (not useful for making any general conclusions), \emph{observational studies} (better than anecdotes), \emph{experiments} (can make causal inferences).

\subsubsection{Observational Studies}

Observe existing characteristics of a subset of individuals in a population(s). The goal is either to draw conclusions about the population or about differences between two or more groups or about the relationship between variables. The investigator has no control over which individuals are in which group, nor any of their characteristics. 

[We just look at the world, but do not influence it]

We have to be cautions when interpreting the results. If we observe an association between the outcome and the explataory variable. There are five situations: first, the changes in the explanatory variable cause the change in the outcome variable (causation - good), second, the changes in the outcome make the explanatory variable change (reverse causation), third, maybe we got lucky, have a coincidence, fourth, both the outcome and the explanatory variable result from a common cause (a hidden variable), fifth, there could be confounding variable (which vary with the explanatory variable and cause the outcome variable as well). When we see the association, we cannot definitely say we are in the first situation. In general, we have \emph{lurking variables}, which can be confounding, hidden variables, or another variable that, when considered, changes the nature of the association. 

\subsubsection{Experiments}

Interventions are imposed  by the investigator on the subjects. Gold standard for causal conclusions.

[We influence the world and observe the results]

The \emph{response variable} (the \emph{dependent variable}) - the outcome of interest, measured on each subject participating in the experiment.

The \emph{explanatory variables} (or \emph{predictor} or \emph{independent variable}) a variable that we think might help to explain the value of the response variable.

The main difference between an observational study and an experiment is that the researcher manipulates the explanatory variables to the see the effect on the response.

In an experiment the exploratory variable is usually categorical. This is called an \emph{factor}. The values of a factor are its \emph{levels}. A particular combination of values for the factors is called a \emph{treatment}. An \emph{experimental unit} is the smallest unit to which a treatment is applied (one human, one class in a school, one greenhouse worth of pots of plants etc.).

The main difference is then is that treatments are imposed by the researcher on the experimental units, so that the effects of the treatment on the response can be seen.

\emph{Extraneous factors} are not of interest in the current study, but are thought to affect the response. We have several approaches \emph{to control} for an identified extraneous factor. First, we can hold it \emph{constant}. This limits the generalizability of the study, but also limits the potential of having the extraneous variable confound the results. Second, we can use \emph{blocking}. A \emph{block} is a group of experimental units that are similar. All treatments are assigned to experimental units withing each block. If we have extraneous variables we can't control or we don't know about (which is most likely the case), we must use \emph{randomisation} to assign experimental units to treatment groups. We can insure that any differences that exist in any possible extraneous variables are due to chanche. We can also account for this variability in the statistical model. Once we average out the chanhce variation, the treatement groups are essentially the same. Once you've eliminated other differences between the treatment groups, if the response variable is different among the groups, the only explanation is the treatment and, therefore, causal conclusions can be made.

We also need to do \emph{replication} : apply each treatement to more than one experimental unit - this allows variability measures for response and ensures that the treatment groups are more comparable in values of the extraneous variables, by having the opportunity to see more than one such variable.

An \emph{control group} is a group of individiduals which does not receive a treatment or receives the current standard treatment. It is used to make comparisons with a treatment of interest.

Another concept is \emph{blinding}. Experimental units are blinded if they do not know what treatement they have received. The researched is blinded if he/she does not know which treatment was given to each experimental unit. Experiments can be single-blind (only one type of blinding, most common the experimental unit one) or double-blind (both types of blinding). This reduces the potential for bias, but is not always possible. One cause of the bias, in experimental units, is the \emph{Placebo effect}. The control group is given a \emph{placebo} as a tratement - a treatement which has no effect, but which does not allow the experimental unit (if it is a human, of course) to know this.

Causal conclusions are only establish through a randmised controlled experiments. It is not always possible to design such an experiment, for ethical or practical reasons.

To summarize, we can have randomisation in the selection of experimental units (the sample), and the assignment of treatements. If both are random, then we can make causal conclusions that can be generalised to the population. If selection is random, but assignments are not, we cannot make causal conclusions, but the results can be generalised to the population. If selection is not random, but assignments are, we can make causal conclusions about only the participating experimental units. If both are not random, we cannot interpret any observed relationships as causal and cannot generalise beyond the participating experimental units.

define {Data Gathering Process} {
  How we gather data for a data analysis.
}

define {Observational Study} {
  A type of data gathering where we only observer the data, and try to not interfere with the data generating process.
  We can only talk about relationship between variables, although in many cases there is prediction we can do. Eg - does a picture of a cat determine the "cat" label or the "cat" label determine the picture? Does not necessarily matter, but once we have a good model of the relationship between an image and the "cat" label we can use this to predict whether we have an image of a cat or not.
  Only measure variables.
  Retrospective and prospective study.
}

define {Experiment} {
  [Typical experiment talk]
  The explanatory variables are assigned by the researchers.
  Principles:
    Controlling - assign subjects to treatments and try to "control" all other variables (which may or may not be measured) - reduce variability in the cases.
    Randomization - do the assignment randomly so the remaining variation is evenly split between the treatments.
    Replication - use more than one subject per treatment. Also, others can repeat the experiment.
    Blocking - if we suspect another variable can influence the response, but can't control for it, we might group subjects by it, and do randomization it it (similar to stratified sampling).
  Blind and double-blind study.
}

=== Samples And Sampling Methods ===

\subsection{Sampling and Estimation}

The observed value of an estimator varies from sample of data to sample of data. The variability is called the \emph{sampling variability}. The probability distribution of the values of an estimator is its \emph{sampling distribution}.

An \emph{unbiased estimator} of a parameter $\Omega$ is one for which the expected value of its sampling distribution is equal to the value of the parameter being estimated, or $E[\hat{\Omega}] = \Omega$.

A coin flip experiment. Suppose we have $X ~ \text{Bernoulli}(p)$. Then $E[X] = p$. If we have $10$ flips, with outcomes $X_1,X_2,\dots,X_{10}$, we have the estimator $\hat{p} = (X_1 + \dots + X_{10}) / 10 = \overline{X}$. Since $E[X_i] = p$ in the framework of data generation, then $E[\hat{p}] = p$, as well, because $E$ is linear. Therefore, when we estimate the probability of something happening $p$, by the proportion of it happening $\hat{p}$ in a number of independent experiments, then the sampling distribution of $\hat{p}$ has mean $p$, therefore the estimator is unbiased. But in any one sample, are we likely to be close? We need to talk about its variance. We have $V[X] = p(1-p)$. We have $V[\hat{p}] = p(1 - p) / n$ and $SD[\hat{p}] = \sqrt{p(1 - p) / n}$. This drops with sample size (very good). We get more precise estimates as $n$ increases. The sampling distribution is $\text{Binom}[n,p]$. For large sample sizes, by the CTL, a good approximation fo the sampling distribution is $\mathcal{N}(p,p(1 - p)/n)$. This is good though for $p$ closer to $0.5$. For farther away from it, we need an even larger sample size.

[pictures of sampling distributions for different sizes of $n$]

$n$ measurements of a real world quantity with normal distribution. $X ~ \mathcal{N}[\mu,\sigma^2]$. The estimator of $\mu$ is $\hat{\mu} = (X_1 + \dots + X_n)$. The expected value of $\hat{\mu}$ is $E[\hat{\mu}] = \mu$. Therefore $\hat{\mu}$ is an unbiased estimator of $\mu$. The variance is $V[\mu] = \sigma^2/n$ - again, this drops with the sample size. Using the CTL, we have that $\hat{\mu} ~ \mathcal{N}[\mu,\sigma^2/n]$. 

This same result holds for other types of distributions, because of the linearity of expectation. For skewed distributions and smaller $n$ we will see a skew in the sampling distribution, however, because the CLT hasn't kicked in well.

Proportions and means are interesting in many practical applications. That's why we usually focus on them.

define {Issues With Simple Random Sampling} {
  Non response bias => makes the sample be unrepresentative - we can only say things about people who would respond to our survey.
  Convenience sample => makes the sample be unrepresentative - we can only say things about people who are easy to survey.
}

define {SRS} {
  Each observation is equally likely to be in the sample and knowing that one is in the sample does not affect others (independence).
}

define {Stratified Sampling} {
  Split the data into groups, and then do SRS in each group.
  Prevents randomness in small sample situations from producing results which skew the results very much.
  Useful when the cases in each strata are very similar, but the intra-strata data might have problems.
}

define {Cluster Sampling} {
  Split the data into clusters, randomly sample clusters, then randomly sample from every cluster.
  Useful when each cluster has high variability, but the clusters themselves are not that different.
}

define {Sample} {
  A small subset of a larger set of data, used to make inferences about the larger set.
  A sample should be random, representative (unbiased).
  define {Sampling} {
    Obtaining a sample from a population.
    The sampling procedure, rather than the results of the procedure define what it means for the sample to be random.
  }
  Size matters - a random sample of small size might not be representative.
  Lack of randomness or being non-representative or biased restricts the generalizability of the results to the subset of the population the sample is random/representative/unbiased.
}

define {Simple Random Sampling} {
  A technique for building a sample from a population, where each element of the population has an equal probability of being included in the sample. The selection of one element must be independent of the selection of every other element (picking one element must not increase/decrease the probability of picking any other element, relative to the others).
  Sometimes this is difficult to do - if the population is not completely known or it varies a in time such that the time taken by sampling procedure is not trivial.
}

define {Random Assignment} {
  A technique for building a sample from a population. The population is often hypothetical.
  Elements are divided in groups, randomly. If this is not done randomly, then the results are usually erronous.
}

define {Stratified Sampling} {
  A techinque for building a sample from a population which has a known set of distinct "strata" or groups. Simple random sampling is performed in each group, and the sub-samples are combined to form the full sample, which is representative of the whole population.
}

define {Anectodal Evidence} {
  Data collected in a haphazard fashion. It might represent extreme cases (likely to be remembered) or be unrepresentative of the population in some way, may be poorly collected etc.
}


